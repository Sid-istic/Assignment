

# ğŸ§© **Kasparro Agentic Facebook Analyst â€“ Assignment Submission**

This repository contains my implementation of the **Agentic Facebook Analyst System**, as specified in the assignment PDF.
The project follows a fully modular, multi-agent design where each agent performs one stage of the analysis pipeline (planning â†’ data analysis â†’ insight generation â†’ evaluation â†’ creative generation).

---

# ğŸš€ **1. Overview**

This project simulates an **agentic AI system** designed to perform:

* Facebook Ads data analysis
* ROAS & CTR diagnosis
* Hypothesis generation
* Insight evaluation with confidence scoring
* Creative improvement generation
* Complete agent-to-agent orchestration

The system is built using **Python**, following the exact architecture described in the assignment.
No LLM calls are required; rule-based agents are implemented so the project runs **without API keys**.

---

# ğŸ§  **2. System Architecture**

The system uses **five agents**, coordinated by an **Orchestrator**:

### **1. Planner Agent**

* Breaks down the user query
* Produces ordered tasks
* Defines dependencies between agents

### **2. Data Agent**

* Loads Facebook Ads dataset
* Validates required columns
* Produces global metrics, ROAS trends, CTR trends
* Identifies low-CTR ads

### **3. Insight Agent**

* Generates hypotheses based on the data
* Hypotheses follow assignment-required structure

### **4. Evaluator Agent**

* Validates each hypothesis
* Computes quantitative evidence (ROAS drop, CTR drop, spend share, etc.)
* Assigns a confidence score: **high / medium / low**

### **5. Creative Agent**

* Uses data from low-CTR ads
* Generates improved creative ideas, headlines, hooks, and CTAs
* Outputs marketer-ready suggestions

### **Orchestrator**

* Manages the full workflow end-to-end
* Logs JSON traces for each stage
* Writes final insights & creative recommendations
* Generates a final human-readable `report.md`

---

# ğŸ“‚ **3. Repository Structure**

```
kasparro-agentic-fb-analyst/
â”‚
â”œâ”€â”€ run.py
â”œâ”€â”€ README.md
â”œâ”€â”€ agent_graph.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â”œâ”€â”€ run.sh
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ planner.py
â”‚   â”‚   â”œâ”€â”€ data_agent.py
â”‚   â”‚   â”œâ”€â”€ insight_agent.py
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py
â”‚   â”‚   â””â”€â”€ creative_agent.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ logging_utils.py
â”‚       â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ planner_prompt.md
â”‚   â”œâ”€â”€ data_agent_prompt.md
â”‚   â”œâ”€â”€ insight_agent_prompt.md
â”‚   â”œâ”€â”€ evaluator_prompt.md
â”‚   â””â”€â”€ creative_prompt.md
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_fb_ads.csv
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ report.md
â”‚   â”œâ”€â”€ insights.json
â”‚   â””â”€â”€ creatives.json
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_evaluator.py
```

---

# âš™ï¸ **4. Installation & Setup**

## **Create environment**

```bash
python -m venv .venv
.venv\Scripts\activate     # Windows
source .venv/bin/activate  # Mac/Linux
```

## **Install dependencies**

```bash
pip install -r requirements.txt
```

## **Run the system**

```bash
python run.py "Analyze ROAS drop"
```

Outputs will appear in the `reports/` folder.

---

# ğŸ“Š **5. Input & Output Expectations**

### **Input**

A marketer-style query, such as:

> â€œAnalyze ROAS drop and find likely causes.â€

### **Output (Generated Automatically)**

#### 1. **insights.json**

Structured hypotheses with:

* Title
* Description
* Driver
* Reasoning
* Confidence
* Evidence

#### 2. **creatives.json**

New creative suggestions with:

* Headline
* Primary text
* CTA
* Based on original creative message

#### 3. **report.md**

A clean, marketer-friendly summary including:

* Account summary
* Hypotheses + confidence
* Creative improvement ideas

#### 4. **JSON Logs (Traces)**

Stored in `logs/`:

* planner trace
* data summary trace
* insight generation trace
* evaluation trace
* creative generation trace

(As required by assignment.)

---

# ğŸ“ **6. Prompts (LLM Design Requirement)**

The `prompts/` directory contains:

* Planner Agent Prompt
* Data Agent Prompt
* Insight Agent Prompt
* Evaluator Agent Prompt
* Creative Agent Prompt

Each prompt includes:

* **Think â†’ Analyze â†’ Conclude** format
* **Strict JSON output** requirements
* Agent roles
* Instructions for deterministic output

These satisfy the prompt engineering requirements in the assignment.

---

# ğŸ§ª **7. Tests**

A minimal unit test is included:

```
tests/test_evaluator.py
```

It validates the confidence scoring logic of the Evaluator Agent.

---

# ğŸ§± **8. Reproducibility**

The system uses:

* Seeded randomness
* Version-pinned `requirements.txt`
* Sample dataset (`sample_fb_ads.csv`)
* Config-driven thresholds
* Generated logs and reports committed for review

---

# ğŸ·ï¸ **9. Versioning**

The repository includes:

* Multiple commits
* Clear commit messages
* A **v1.0 tag** as required
* A **self-review pull request** describing the system
  (as per assignment instructions)

---

# ğŸ“Œ **10. How to Run for Review**

To reproduce the final output:

```bash
python run.py "Analyze ROAS drop"
```

The evaluator will find:

* ROAS degradation (if present)
* CTR decline
* Underperforming campaigns
* Low-CTR creatives needing refresh

Creatives and insights appear under `reports/`.

---

# ğŸ¯ **11. Key Features Implemented (Matching PDF Requirements)**

* âœ” Multi-agent architecture
* âœ” Clear agent roles & boundaries
* âœ” Functional pipeline
* âœ” JSON traces for each stage
* âœ” Error handling
* âœ” Data validation
* âœ” Hypothesis generation
* âœ” Confidence scoring + evidence
* âœ” Creative variant generation
* âœ” Final report in markdown
* âœ” Git versioning & tagging
* âœ” Self-review PR
* âœ” No API keys required
* âœ” Deterministic output

---

# ğŸ **12. Final Notes**

This project is built to match the exact expectations of the assignment, including:

* Reproducibility
* Agent-to-agent orchestration
* Comprehensive reporting
* Well-documented code
* A clear, professional repository

If needed, I can also create:

âœ… A professional self-review
âœ… A GitHub PR description
âœ… A demo video script

Just tell me!
